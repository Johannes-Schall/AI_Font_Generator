{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forcing the notebook to reload the modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7895\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7895/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29048/2870543135.py:200: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed two minor releases later. Use buffer_rgba instead.\n",
      "  return PIL.Image.frombytes('RGB', fig.canvas.get_width_height(),fig.canvas.tostring_rgb())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johannes/AI_Font_Generator/src/app/gradio/../../../src/data/datarenderer.py:70: RuntimeWarning: overflow encountered in cast\n",
      "  arrays = np.empty((len(font_file_paths), size, size, len(chars))).astype(dtype)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from src.data import datarenderer as dr\n",
    "from src.data import datafilter as df\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data import fontdb_handler as fh\n",
    "import datetime\n",
    "from contextlib import redirect_stdout\n",
    "from src.model import helperfunctions as hf\n",
    "import PIL\n",
    "from zipfile import ZipFile\n",
    "\n",
    "charset_in = \"AaOoUu8Bj\"\n",
    "charset_out = \"ÄäÖöÜüß\"\n",
    "box_size = 64\n",
    "\n",
    "class AutoEncoder(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, latent_dim, *args, **kwargs):\n",
    "    assert isinstance(latent_dim, int)\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.latent_dim = latent_dim\n",
    "\n",
    "    self.inverter_layer = lambda x: 1 - x\n",
    "\n",
    "    # Encoder\n",
    "    self.encoder_conv2d_1 = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")\n",
    "    self.encoder_maxpool_1 = layers.MaxPooling2D((2, 2), padding=\"same\")\n",
    "    self.encoder_conv2d_2 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")\n",
    "    self.encoder_maxpool_2 = layers.MaxPooling2D((2, 2), padding=\"same\")\n",
    "    self.encoder_dropout_1 = layers.Dropout(0.1)\n",
    "    self.encoder_conv2d_3 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")\n",
    "    self.encoder_maxpool_3 = layers.MaxPooling2D((2, 2), padding=\"same\")\n",
    "    self.encoder_flatten = layers.Flatten()\n",
    "    self.encoder_dropout_2 = layers.Dropout(0.1)\n",
    "    self.encoder_fc1 = layers.Dense(512, activation=\"relu\")\n",
    "    self.encoder_dropout_3 = layers.Dropout(0.1)\n",
    "    self.encoder_fc2 = layers.Dense(latent_dim, activation=\"relu\")\n",
    "\n",
    "    # Decoder\n",
    "    self.decoder_dropout_1 = layers.Dropout(0.1)\n",
    "    self.decoder_fc1 = layers.Dense(512, activation=\"relu\")\n",
    "    self.decoder_reshape = layers.Reshape((4, 4, 32))\n",
    "    self.decoder_upsample_1 = layers.UpSampling2D((2, 2))\n",
    "    self.decoder_conv2d_1 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")\n",
    "    self.decoder_dropout_2 = layers.Dropout(0.1)\n",
    "    self.decoder_upsample_2 = layers.UpSampling2D((2, 2))\n",
    "    self.decoder_conv2d_2 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")\n",
    "    self.decoder_dropout_3 = layers.Dropout(0.1)\n",
    "    self.decoder_upsample_3 = layers.UpSampling2D((2, 2))\n",
    "    self.decoder_conv2d_3 = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")\n",
    "    self.decoder_out = layers.Conv2DTranspose(len(charset_out), (3, 3), strides=(2, 2), padding=\"same\")\n",
    "\n",
    "    self._build_graph()\n",
    "\n",
    "  def _build_graph(self): # Just here because we want to see the output shapes in the summary.\n",
    "    input_shape = (box_size, box_size, len(charset_in))\n",
    "    self.build( (None,) + input_shape )\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    _ = self.call(inputs)\n",
    "\n",
    "  def call(self, x):\n",
    "    z = self.encode(x)\n",
    "    y = self.decode(z)\n",
    "    return y\n",
    "\n",
    "  def encode(self, x):\n",
    "    encoded = self.inverter_layer(x)\n",
    "    encoded = self.encoder_conv2d_1(encoded)\n",
    "    encoded = self.encoder_maxpool_1(encoded)\n",
    "    encoded = self.encoder_conv2d_2(encoded)\n",
    "    encoded = self.encoder_maxpool_2(encoded)\n",
    "    #encoded = self.encoder_dropout_1(encoded)\n",
    "    encoded = self.encoder_conv2d_3(encoded)\n",
    "    encoded = self.encoder_maxpool_3(encoded)\n",
    "    encoded = self.encoder_flatten(encoded)\n",
    "    #encoded = self.encoder_dropout_2(encoded)\n",
    "    encoded = self.encoder_fc1(encoded)\n",
    "    #encoded = self.encoder_dropout_3(encoded)\n",
    "    encoded = self.encoder_fc2(encoded)\n",
    "    return encoded\n",
    "\n",
    "  def decode(self, decoded):\n",
    "    #decoded = self.decoder_dropout_1(decoded)\n",
    "    decoded = self.decoder_fc1(decoded)\n",
    "    decoded = self.decoder_reshape(decoded)\n",
    "    decoded = self.decoder_upsample_1(decoded)\n",
    "    decoded = self.decoder_conv2d_1(decoded)\n",
    "    #decoded = self.decoder_dropout_2(decoded)\n",
    "    decoded = self.decoder_upsample_2(decoded)\n",
    "    decoded = self.decoder_conv2d_2(decoded)\n",
    "    #decoded = self.decoder_dropout_3(decoded)\n",
    "    decoded = self.decoder_upsample_3(decoded)\n",
    "    decoded = self.decoder_conv2d_3(decoded)\n",
    "    decoded = self.decoder_out(decoded)\n",
    "    decoded = self.inverter_layer(decoded)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def generate_umlaute(file):\n",
    "    array_chars_in = dr.render_fonts([file], chars=charset_in, size=box_size, normalize=True)\n",
    "    array_chars_out = model.predict(array_chars_in)\n",
    "    temp = 0.05\n",
    "    prediction = 1 / (1 + np.exp(-(array_chars_out[0,:,:,:] - 0.5)/temp))\n",
    "    return prediction\n",
    "\n",
    "def plot_char_table(file, umlaut_array=None):\n",
    "    \"\"\"\n",
    "    Plots the character table for the given font file. Like\n",
    "      0 1 2 3 4 5 6 7 8 9\n",
    "\n",
    "      A B C D E F G H I J\n",
    "      K L M N O P Q R S T\n",
    "      U V W X Y Z \n",
    "      \n",
    "      a b c d e f g h i j\n",
    "      k l m n o p q r s t\n",
    "      u v w x y z\n",
    "\n",
    "      Ä ä Ö ö Ü ü ß\n",
    "\n",
    "    Args:\n",
    "        file (str): path to the font file\n",
    "    \"\"\"\n",
    "    chars_numbers = \"0123456789\"\n",
    "    chars_upper = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    chars_lower = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    chars_umlaut = \"ÄäÖöÜüß\"\n",
    "\n",
    "    fig, axs = plt.subplots(11, 10, figsize=(7.5,15))\n",
    "    if umlaut_array is None:\n",
    "        suptitle = \"Table of characters for font \" + os.path.basename(file)\n",
    "    else:\n",
    "        suptitle = \"Complete table of characters for font \" + os.path.basename(file)\n",
    "    fig.suptitle(suptitle)\n",
    "\n",
    "    for i in range(10):\n",
    "        axs[0, i].imshow(\n",
    "            dr.render_font(file, size=box_size, chars=chars_numbers[i], normalize=True)[:,:,0],\n",
    "            cmap=\"gray\"\n",
    "        )\n",
    "        axs[0, i].axis('off')\n",
    "        # Titles in light gray\n",
    "        axs[0, i].set_title(chars_numbers[i], color=\"lightgray\")\n",
    "    for i in range(10):\n",
    "        # Empty plot\n",
    "        axs[1, i].axis('off')\n",
    "    for i in range(30):\n",
    "        if i < len(chars_upper):\n",
    "            axs[2 + i // 10, i % 10].imshow(\n",
    "                dr.render_font(file, size=box_size, chars=chars_upper[i], normalize=True)[:,:,0],\n",
    "                cmap=\"gray\"\n",
    "            )\n",
    "            axs[2 + i // 10, i % 10].axis('off')\n",
    "            axs[2 + i // 10, i % 10].set_title(chars_upper[i], color=\"lightgray\")\n",
    "        else:\n",
    "            # Empty plot\n",
    "            axs[2 + i // 10, i % 10].axis('off')\n",
    "    for i in range(10):\n",
    "        # Empty plot\n",
    "        axs[5, i].axis('off')\n",
    "    for i in range(30):\n",
    "        if i < len(chars_lower):\n",
    "            axs[6 + i // 10, i % 10].imshow(\n",
    "                dr.render_font(file, size=box_size, chars=chars_lower[i], normalize=True)[:,:,0],\n",
    "                cmap=\"gray\"\n",
    "            )\n",
    "            axs[6 + i // 10, i % 10].axis('off')\n",
    "            axs[6 + i // 10, i % 10].set_title(chars_lower[i], color=\"lightgray\")\n",
    "        else:\n",
    "            # Empty plot\n",
    "            axs[6 + i // 10, i % 10].axis('off')\n",
    "    for i in range(10):\n",
    "        # Empty plot\n",
    "        axs[9, i].axis('off')\n",
    "    for i in range(10):\n",
    "        if i < len(chars_umlaut):\n",
    "            if umlaut_array is None:\n",
    "                axs[10, i].imshow(\n",
    "                    dr.render_font(file, size=box_size, chars=chars_umlaut[i], normalize=True)[:,:,0],\n",
    "                    cmap=\"gray\"\n",
    "                )\n",
    "            else:\n",
    "                axs[10, i].imshow(\n",
    "                    umlaut_array[:,:,i],\n",
    "                    cmap=\"gray\"\n",
    "                )\n",
    "            axs[10, i].axis('off')\n",
    "            axs[10, i].set_title(chars_umlaut[i], color=\"lightgray\")\n",
    "        else:\n",
    "            # Empty plot\n",
    "            axs[10, i].axis('off')\n",
    "          \n",
    "    fig.canvas.draw()\n",
    "    return PIL.Image.frombytes('RGB', fig.canvas.get_width_height(),fig.canvas.tostring_rgb())\n",
    "\n",
    "def get_font_file(file):\n",
    "    \"\"\"\n",
    "    Loads the font file and displays the character table and the text analysis.\n",
    "    \"\"\"\n",
    "    # Displaying the character table\n",
    "    image = plot_char_table(file)\n",
    "    # Displaying the text analysis\n",
    "    text_analysis = analyse_font_file(file)\n",
    "    return image, text_analysis\n",
    "\n",
    "def plot_repaired_table(file, umlaut_array):\n",
    "    image = plot_char_table(file, umlaut_array)\n",
    "    return image\n",
    "\n",
    "def analyse_font_file(file):\n",
    "    return df.analyse_font_file(file)\n",
    "\n",
    "def repair_table(file):\n",
    "    umlaut_array = generate_umlaute(file)\n",
    "    image = plot_repaired_table(file, umlaut_array)\n",
    "    # Saving the arrays as zip file. Shape: (64, 64, 8)\n",
    "    file_name = os.path.basename(file)\n",
    "    file_name = f\"generated_characters_for_{file_name}.zip\"\n",
    "    with ZipFile(file_name, \"w\") as zip_file:\n",
    "        for i, char in enumerate(list(charset_out)):\n",
    "            PIL.Image.fromarray(np.uint8(umlaut_array[:,:,i] * 255)).filter(PIL.ImageFilter.GaussianBlur(radius=0.5)).save(f\"{char}.png\")\n",
    "            zip_file.write(f\"{char}.png\")\n",
    "            os.remove(f\"{char}.png\")\n",
    "    return image, file_name\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    font_file = gr.File(file_types=[\".ttf\", \".otf\", \".woff\", \".woff2\"])\n",
    "    load_file_button = gr.Button(\"Load file\")\n",
    "    glyph_table_raw = gr.Image()\n",
    "    text_analysis = gr.Text()\n",
    "    repair_button = gr.Button(\"Repair Font File\")\n",
    "    glyph_table_repaired = gr.Image()\n",
    "    download_file = gr.File(label=\"Download\", interactive=False)\n",
    "\n",
    "    load_file_button.click(get_font_file, inputs=font_file, outputs=[glyph_table_raw, text_analysis])\n",
    "    repair_button.click(repair_table, inputs=font_file, outputs=[glyph_table_repaired, download_file])\n",
    "   \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # loading the keras model\n",
    "    model = tf.keras.models.load_model(\"../../../models/20231125_174320_val_loss_0.0174_train_loss_0.0138_model.keras\",\n",
    "                                       custom_objects={\"AutoEncoder\": AutoEncoder})\n",
    "    demo.launch(show_api=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
